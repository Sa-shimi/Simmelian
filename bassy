from SALib.sample import morris
import random
import networkx as nx
import pandas as pd
from itertools import combinations
from random import randrange
from SALib.analyze.morris import analyze
import statistics as s
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.cm as cm



def plottare (q):
    m=0


    def tutto():

        threshold=0.1
        p = 3
        num = 100
        F = nx.random_tree(n=num, create_using=nx.DiGraph, )
        G = nx.barabasi_albert_graph(num, p)
        pos = nx.circular_layout(F)

        nx.set_node_attributes(G, 0, name='relevance')
        primi = random.sample(range(0, num), 1)
        print(primi)
        for n in primi:
                    G.nodes[n]['relevance'] = 1

        nx.set_edge_attributes(G, 0, name='threshold')

        def Control_Centrality(F):
            length = len(F.nodes)
            i = 1

            def CC(F):
                pippa = F.out_degree()
                pippa1 = np.array(pippa)
                pippa2 = pippa1[pippa1[:, 1] != 0]
                F = F.subgraph(pippa2[:, 0])
                return F
            def layer(F):
                culo = [x for x in F.nodes if x not in CC(F).nodes]
                banana = [i] * len(culo)
                results = np.column_stack((culo, banana))
                return results

            results = layer(F)
            while len(results) < length:
                results = np.concatenate([results, layer(F)])
                results = np.unique(results, axis=0)
                i += 1
                F = CC(F)
                layer(F)
            return dict(zip(results[:, 0], (results[:, 1])))
        BC = Control_Centrality(F)
        def find_simmelian(G):
            cliques = list(nx.enumerate_all_cliques(G))

            triads = [i for i in cliques if len(i) == 3]

            def combine(arr, s):
                return list(combinations(arr, s))

            simm = []
            for n in triads:
                for l in combine(n, 2):
                    simm.append(l)

            simmelian = []
            for i in simm:
                if i not in simmelian:
                    simmelian.append(i)
            return(simmelian)

        simmelian = np.array(find_simmelian(G))
        A = simmelian[:, 0]
        B = simmelian[:, 1]
        df = pd.DataFrame(simmelian)
        BCA = []
        for x in (A):
            for n in (BC):
                if x == n:
                    BCA.append(BC[n])
        BCB = []
        for y in (B):
            for n in (BC):
                if y == n:
                    BCB.append(BC[n])
        df['BCA'] = BCA
        df['BCB'] = BCB
        df['AVG'] = (df['BCA'] + df['BCB']) / 2
        df['VAR'] = (((df['BCA'] - df['AVG']) ** 2 + (df['BCB'] - df['AVG']) ** 2) / 2)
        VAR = np.sum(df['VAR'])
        for n in G.nodes:
            G.nodes[n]['threshold'] = abs((BC[n]/BC[0])-1)
        nx.set_edge_attributes(G, 0, name='imitation')
        for n in G.nodes:
            G.nodes[n]['imitation'] = randrange(1,10)/100

        def bass(G):
            K=G.copy()
            t=1
            def event(G):
                nonsimmy=[]
                simmy=[]
                for n in K.nodes:
                    if K.nodes[n] in simmelian:
                        if K.nodes[n]['relevance']==1:
                            simmy.append(n)
                    elif K.nodes not in simmelian:
                        if K.nodes[n]['relevance']==1:
                            nonsimmy.append(n)
                prob=((len(simmy)*5)+len(nonsimmy))/len(G.nodes)
                for i in K.nodes:
                    if K.nodes[i]['relevance'] <= threshold:
                        opchange=[]
                        if random.random()< G.nodes[i]['imitation']*prob:
                            K.nodes[i]['relevance'] = 1
                return K
            dati=[]
            while t!=500:
                t+=1
                event(K)
                P=[]
                for n in K.nodes:
                    if K.nodes[n]['relevance']>=threshold:
                        P.append(K.nodes[n]['relevance'])
                dati.append((len(P)/num))
            return dati
    


        return [bass(G)]


        DATONIdegroot = []
        DATONIcontagion=[]
        DATONIbass=[]

        while m!= q:
            m += 1
            DATONIdegroot.append(tutto()[0])
            DATONIcontagion.append(tutto()[1])
            DATONIbass.append(tutto()[2])
        dat = np.array(DATONIdegroot)
        fig, (tot, value) = plt.subplots(2, 1)
        for n in dat:
            tot.plot(n, 'k', alpha=0.05)
        lst = []
        n = len(tutto()[0])
        for i in range(n + 0):
            lst.append(i)
        minimo = []
        massimo = []
        media = []
        mediana = []

        for l in np.array(lst):
            minimo.append(dat[:, l].min())
            massimo.append(dat[:, l].max())
            media.append(dat[:, l].mean())
            mediana.append(np.median(dat[:, l], axis=0))

        value.plot(minimo)
        value.plot(massimo)
        value.plot(media)
        value.plot(mediana, 'r--')


        datcontagion = np.array(DATONIcontagion)
        fig, (tot, value) = plt.subplots(2, 1)
        for n in datcontagion:
            tot.plot(n, 'k', alpha=0.05)
        lstcontagion = []
        n = len(tutto()[1])
        for i in range(n + 0):
            lstcontagion.append(i)
        minimo = []
        massimo = []
        media = []
        mediana = []
        print(datcontagion)
        for l in np.array(lstcontagion):
            minimo.append(datcontagion[:, l].min())
            massimo.append(datcontagion[:, l].max())
            media.append(datcontagion[:, l].mean())
            mediana.append(np.median(datcontagion[:, l], axis=0))

        value.plot(minimo)
        value.plot(massimo)
        value.plot(media)
        value.plot(mediana, 'r--')
        datbass = np.array(DATONIbass)
        fig, (tot, value) = plt.subplots(2, 1)
        for n in datbass:
            tot.plot(n, 'k', alpha=0.05)
        lstbass = []
        n = len(tutto()[2])
        for i in range(n + 0):
            lstbass.append(i)
        minimo = []
        massimo = []
        media = []
        mediana = []

        for l in np.array(lstbass):
            minimo.append(datbass[:, l].min())
            massimo.append(datbass[:, l].max())
            media.append(datbass[:, l].mean())
            mediana.append(np.median(datbass[:, l], axis=0))

        value.plot(minimo)
        value.plot(massimo)
        value.plot(media)
        value.plot(mediana, 'r--')

        plt.show()
