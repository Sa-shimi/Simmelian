import random
import networkx as nx
import pandas as pd
from itertools import combinations
from random import randrange
import numpy as np
import matplotlib.pyplot as plt
import time



num = 200


def plottare(iters, steps):
    m = 0
    def tutto():
        p = 3

        F = nx.random_tree(n=num, create_using=nx.DiGraph, )
        G = nx.barabasi_albert_graph(num, p)

        def combine(arr, s):
            return list(combinations(arr, s))

        def Control_Centrality(F):
            length = len(F.nodes)
            i = 1

            def CC(F):
                pippa = F.out_degree()
                pippa1 = np.array(pippa)
                pippa2 = pippa1[pippa1[:, 1] != 0]
                F = F.subgraph(pippa2[:, 0])
                return F

            def layer(F):
                culo = [x for x in F.nodes if x not in CC(F).nodes]
                banana = [i] * len(culo)
                results = np.column_stack((culo, banana))
                return results

            results = layer(F)
            while len(results) < length:
                results = np.concatenate([results, layer(F)])
                results = np.unique(results, axis=0)
                i += 1
                F = CC(F)
                layer(F)
            return dict(zip(results[:, 0], (results[:, 1])))

        BC = nx.betweenness_centrality(F)

        isinstance(BC, dict)
        list(G.nodes)

        lll = combinations(G.nodes(), 2)
        lll = np.matrix(list(lll))
        cliques = list(nx.enumerate_all_cliques(G))
        triads = [i for i in cliques if len(i) == 3]
        simm = []
        for n in triads:
            for l in combine(n, 2):
                simm.append(l)

        simmelian = []
        for i in simm:
            if i not in simmelian:
                simmelian.append(i)

        simmelian = np.array(simmelian)

        A = simmelian[:, 0]
        B = simmelian[:, 1]
        A1 = lll[:, 0]
        B1 = lll[:, 1]
        df = pd.DataFrame(simmelian)
        numsimm = len(simmelian)

        BCA = []
        for x in A:
            for n in BC:
                if x == n:
                    BCA.append(BC[n])
        BCB = []
        for y in B:
            for n in BC:
                if y == n:
                    BCB.append(BC[n])

        df['BCA'] = BCA
        df['BCB'] = BCB
        df['AVG'] = (df['BCA'] + df['BCB']) / 2
        df['VAR'] = (((df['BCA'] - df['AVG']) ** 2 + (df['BCB'] - df['AVG']) ** 2) / 2)
        VAR = np.sum(df['VAR'])
        V = VAR / numsimm
        df1 = df[3:4]
        dff = []
        for k in G.nodes:
            for n in BC:
                if k == n:
                    dff.append(BC[n])
        T = max(dff)

        H = pd.DataFrame(dff)
        H['BCMax'] = T
        H.rename(columns={0: 'BCentrality'}, inplace=True)
        H['Hier'] = (H['BCMax'] - H['BCentrality'])
        Q = np.mean(H['Hier'])
        v = Q * V

        BC1 = nx.betweenness_centrality(F)
        isinstance(BC1, dict)
        df1 = pd.DataFrame(lll)
        BC1A = []
        for x in A1:
            for n in BC1:
                if x == n:
                    BC1A.append(BC1[n])
        BC1B = []
        for y in B1:
            for n in BC1:
                if y == n:
                    BC1B.append(BC1[n])
        df1['BC1A'] = BC1A
        df1['BC1B'] = BC1B
        df1['AVG1'] = (df1['BC1A'] + df1['BC1B']) / 2
        df1['VAR1'] = ((df1['BC1A'] - df1['AVG1']) ** 2 + (df1['BC1B'] - df1['AVG1']) ** 2) / 2
        V1 = np.mean(df1['VAR1'])
        dff1 = []
        for k in G.nodes:
            for n in BC1:
                if k == n:
                    dff1.append(BC1[n])
        T1 = max(dff1)
        H1 = pd.DataFrame(dff1)
        H1['BC1Max'] = T1
        H1.rename(columns={0: 'BCentrality1'}, inplace=True)
        H1['Hier1'] = (H1['BC1Max'] - H1['BCentrality1'])
        Vl = V / V1
        nx.set_edge_attributes(G, 0, name='imitation')
        for n in G.nodes:
            G.nodes[n]['imitation'] = randrange(1, 10) / 100

        sup = []
        for (i, j) in F.edges:
            sup.append((j, i))

        sub = F.edges

        nx.set_edge_attributes(G, 0, name='theta')
        for n in G.nodes:
            G.nodes[n]['theta'] = randrange(1, 10) / 500
        nx.set_edge_attributes(G, 0, name='ego')
        for n in G.nodes:
            G.nodes[n]['ego'] = randrange(4, 9) / 10
        nx.set_node_attributes(G, 0, name='relevance')
        primi = random.sample(range(0, num), 1)

        for n in primi:
            G.nodes[n]['relevance'] = 1

        nx.set_edge_attributes(G, 0, name='threshold')
        for n in G.nodes:
            G.nodes[n]['threshold'] = np.random.beta(1, 10)

        influence_matrix = np.matrix(np.zeros((num, num)))
        for i in G.nodes:
            for j in G.nodes:
                if i != j:
                    if j in G.neighbors(i):
                        if BC[i] - BC[j] < 0:
                            influence_matrix[i, j] = (np.random.beta(1, 8) / len(list(G.neighbors(i))))
                        elif BC[i] - BC[j] > 0:
                            influence_matrix[i, j] = np.random.beta(3, 7) / len(list(G.neighbors(i)))
                        elif BC[i] - BC[j] == 0:
                            influence_matrix[i, j] = np.random.beta(4, 3) / len(list(G.neighbors(i)))
            influence_matrix[i, i] = (1 - influence_matrix[[i]].sum(axis=1))


        probability_matrix = np.matrix(np.zeros((num, num)))
        for i in G.nodes:
            for j in G.nodes:
                if i == j:
                    probability_matrix[i, j] = 1
                elif i != j:
                    if [i, j] in simmelian:
                        if BC[i] - BC[j] > 0:
                            probability_matrix[i, j] = np.random.beta(8, 1)
                        elif BC[i] - BC[j] < 0:
                            probability_matrix[i, j] = np.random.beta(8, 1)
                        elif BC[i] - BC[j] == 0:
                            probability_matrix[i, j] = np.random.beta(8, 1)
                    elif [i, j] not in simmelian:
                        if BC[i] - BC[j] > 0:
                            probability_matrix[i, j] = np.random.beta(4, 2)
                        elif BC[i] - BC[j] < 0:
                            probability_matrix[i, j] = np.random.beta(4, 2)
                        elif BC[i] - BC[j] == 0:
                            probability_matrix[i, j] = np.random.beta(4, 3)

        def degroot(G):
            K = G.copy()
            t = 1
            bellini = []

            def event():
                P = K.copy()
                for i in K.nodes:
                    opchange = [P.nodes[i]['relevance']*influence_matrix[i,i]]
                    for j in K.neighbors(i):
                        if P.nodes[j]['relevance'] >= P.nodes[j]['threshold']:
                            if random.random() < probability_matrix[i, j]:
                                opchange.append(influence_matrix[i, j])

                    opchange.append(P.nodes[i]['relevance'])
                    K.nodes[i]["relevance"] = np.sum(opchange) - K.nodes[i]['theta']
                return K

            dati = [Vl]
            datelli = []
            while t != steps:
                t += 1
                event()
                P = []
                for n in K.nodes:
                    if K.nodes[n]['relevance'] >= K.nodes[n]['threshold']:
                        P.append(K.nodes[n]['relevance'])
                        if n not in bellini:
                            bellini.append(n)
                dati.append((len(P) / num))
                datelli.append((len(bellini) / num))

            return [dati, datelli]

        def contagion(G):
            K = G.copy()
            t = 1
            bellini = []

            def event():
                P = K.copy()
                for i in K.nodes:
                    opchange = [P.nodes[i]['relevance']*influence_matrix[i,i]]
                    for j in K.neighbors(i):
                        if P.nodes[j]['relevance'] >= P.nodes[j]['threshold']:
                            if random.random() < probability_matrix[i, j]:
                                opchange.append(influence_matrix[i, j] * P.nodes[j]['relevance'])
                            if random.random() > probability_matrix[i, j]:
                                opchange.append(influence_matrix[i, j]*P.nodes[i]['relevance'])
                        if P.nodes[j]['relevance'] >= P.nodes[j]['threshold']:
                            opchange.append(influence_matrix[i, j] * P.nodes[i]['relevance'])
                    K.nodes[i]["relevance"] = np.sum(opchange)

                return K

            dati = [Vl]
            datelli = []
            while t != steps:
                t += 1
                event()
                P = []
                for n in K.nodes:
                    if K.nodes[n]['relevance'] >= K.nodes[n]['threshold']:
                        P.append(K.nodes[n]['relevance'])
                        if n not in bellini:
                            bellini.append(n)
                dati.append((len(P) / num))
                datelli.append((len(bellini) / num))

            return [dati, datelli]

        def bass(G):
            K = G.copy()
            t = 1
            bellini = []

            def event(G):
                nonsimmy = []
                simmy = []
                for i in K.nodes:
                    if K.nodes[i] in simmelian:
                        if K.nodes[i]['relevance'] > K.nodes[i]['threshold']:
                            simmy.append(n)
                    if K.nodes[i] not in simmelian:
                        if K.nodes[i]['relevance'] > K.nodes[i]['threshold']:
                            nonsimmy.append(i)
                prob = ((len(simmy) * Vl) + len(nonsimmy)) / len(G.nodes)
                for i in K.nodes:
                    if K.nodes[i]['relevance'] <= K.nodes[i]['threshold']:
                        if random.random() < G.nodes[i]['imitation'] * prob:
                            K.nodes[i]['relevance'] = 1
                return K

            dati = [Vl]
            datelli = []
            while t != steps:
                t += 1
                event(K)
                P = []
                for n in K.nodes:
                    if K.nodes[n]['relevance'] >= K.nodes[n]['threshold']:
                        P.append(K.nodes[n]['relevance'])
                        if n not in bellini:
                            bellini.append(n)
                dati.append((len(P) / num))
                datelli.append((len(bellini) / num))

            return [dati, datelli]

        return [degroot(G), contagion(G), bass(G), Vl]

    DATONIdegroot = []
    DATONIcontagion = []
    DATONIbass = []
    DATONIphi = []
    cumulativedegroot = []
    cumulativecontagion = []
    cumulativebass = []
    startTime = time.time()
    while m != iters:
        banana = tutto()
        executiontime=(time.time()-startTime)
        m += 1
        print(executiontime)
        print(int((m/iters)*100),'% Estimated time remaining:', int((((executiontime/(m))*(iters-m)))/60), 'minutes')
        DATONIdegroot.append(banana[0][0])
        DATONIcontagion.append(banana[1][0])
        DATONIbass.append(banana[2][0])
        DATONIphi.append(banana[3])
        cumulativedegroot.append((banana[0][1]))
        cumulativecontagion.append((banana[1][1]))
        cumulativebass.append((banana[2][1]))
    dat = np.array(DATONIdegroot)
    fig, (tot, cumulative, value) = plt.subplots(3, 1)
    for n in dat:
        if n[0] < 1:
            tot.plot(n[1:], 'k', alpha=0.1)
        if n[0] > 1:
            tot.plot(n[1:], 'k', alpha=0.1)
    datcumulatividegroot = np.array(cumulativedegroot)
    for n in datcumulatividegroot:
        if n[0] < 1:
            cumulative.plot(n[1:], 'k', alpha=0.1)
        if n[0] > 1:
            cumulative.plot(n[1:], 'b', alpha=0.1)
    lst = []
    n = len(tutto()[0][0])
    for i in range(n + 0):
        lst.append(i)
    minimo = []
    massimo = []
    media = []
    mediana = []

    for l in np.array(lst):
        minimo.append(dat[:, l].min())
        massimo.append(dat[:, l].max())
        media.append(dat[:, l].mean())
        mediana.append(np.median(dat[:, l], axis=0))

    value.plot(minimo[1:])
    value.plot(massimo[1:])
    value.plot(media[1:])
    value.plot(mediana[1:], 'r--')

    datcontagion = np.array(DATONIcontagion)
    fig, (tot, cumulative, value) = plt.subplots(3, 1)
    for n in datcontagion:
        if n[0] < 1:
            tot.plot(n[1:], 'k', alpha=0.1)
        if n[0] > 1:
            tot.plot(n[1:], 'r', alpha=0.1)
    datcumulativicontagion = np.array(cumulativecontagion)
    for n in datcumulativicontagion:
        if n[0] < 1:
            cumulative.plot(n[1:], 'k', alpha=0.1)
        if n[0] > 1:
            cumulative.plot(n[1:], 'r', alpha=0.1)
    lstcontagion = []
    n = len(tutto()[1][0])
    for i in range(n + 0):
        lstcontagion.append(i)
    minimo = []
    massimo = []
    media = []
    mediana = []
    for l in np.array(lstcontagion):
        minimo.append(datcontagion[:, l].min())
        massimo.append(datcontagion[:, l].max())
        media.append(datcontagion[:, l].mean())
        mediana.append(np.median(datcontagion[:, l], axis=0))

    value.plot(minimo[1:])
    value.plot(massimo[1:])
    value.plot(media[1:])
    value.plot(mediana[1:], 'r--')
    datbass = np.array(DATONIbass)
    fig, (tot, cumulative, value) = plt.subplots(3, 1)
    for n in datbass:
        if n[0] < 1:
            tot.plot(n[1:], 'k', alpha=0.1)
        if n[0] > 1:
            tot.plot(n[1:], 'k', alpha=0.1)
    datcumulativibass = np.array(cumulativebass)
    for n in datcumulativibass:
        if n[0] < 1:
            cumulative.plot(n[1:], 'k', alpha=0.1)
        if n[0] > 1:
            cumulative.plot(n[1:], 'b', alpha=0.1)
    lstbass = []
    n = len(tutto()[2][0])
    for i in range(n + 0):
        lstbass.append(i)
    minimo = []
    massimo = []
    media = []
    mediana = []

    for l in np.array(lstbass):
        minimo.append(datbass[:, l].min())
        massimo.append(datbass[:, l].max())
        media.append(datbass[:, l].mean())
        mediana.append(np.median(datbass[:, l], axis=0))

    value.plot(minimo[1:])
    value.plot(massimo[1:])
    value.plot(media[1:])
    value.plot(mediana[1:], 'r--')

    plt.show()
plottare(400, 250)
