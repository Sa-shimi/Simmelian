import random
import statistics
import networkx as nx
import pandas as pd
from itertools import combinations
import numpy as np
import matplotlib.pyplot as plt
from factor_analyzer import FactorAnalyzer
from sklearn.decomposition import FactorAnalysis
import scipy.stats as stats
import statsmodels.api as sm
from statsmodels.formula.api import ols








exp=nx.Graph()
exp.add_edge(0,1)
exp.add_edge(1,2)
exp.add_edge(2,3)
exp.add_edge(4,5)
exp.add_edge(5,6)
exp.add_edge(6,7)
exp.add_edge(8,9)
exp.add_edge(9,10)
exp.add_edge(10,11)
exp.add_edge(12,13)
exp.add_edge(13,14)
exp.add_edge(14,15)

exp.add_edge(0,4)
exp.add_edge(1,5)
exp.add_edge(2,6)
exp.add_edge(3,7)
exp.add_edge(4,8)
exp.add_edge(5,9)
exp.add_edge(6,10)
exp.add_edge(7,11)
exp.add_edge(8,12)
exp.add_edge(9,13)
exp.add_edge(10,14)
exp.add_edge(11,15)
exp.add_edge(12,0)
exp.add_edge(13,1)
exp.add_edge(14,2)
exp.add_edge(15,3)


exp.add_edge(5,10)
nx.draw(exp,with_labels=True)
plt.show()

#G.add_edges_from(seed[0])
#G=nx.watts_strogatz_graph(25,4,0.2)
#G=nx.fast_gnp_random_graph(10,1)

G=exp


rewiring=9
num = len(list(G.nodes))
samples = 5000
steps=100
title='Clique Network'


influence=[]
for n in range(num):
    influence.append([])


top=[0,1,2,3,4,5,12,13,14,15,16,17,24,25,26,27,28,29]
bottom=[6,7,8,9,10,11,18,19,20,21,22,23,30,31,32,33,34,35]
ultravertical = nx.DiGraph()
for n in range(num):
    ultravertical.add_edge(n, n + 1)

F=ultravertical



def test(G):
    l=0





    opinionbanana=[]
    initial_opinion = []
    datas = []
    lll = combinations(G.nodes(), 2)


    def Control_Centrality(F):
        length = len(F.nodes)
        i = 1

        def CC(F):
            pippa = F.out_degree()
            pippa1 = np.array(pippa)
            pippa2 = pippa1[pippa1[:, 1] != 0]
            F = F.subgraph(pippa2[:, 0])
            return F

        def layer(F):
            culo = [x for x in F.nodes if x not in CC(F).nodes]
            banana = [i] * len(culo)
            results = np.column_stack((culo, banana))
            return results

        results = layer(F)
        while len(results) < length:
            results = np.concatenate([results, layer(F)])
            results = np.unique(results, axis=0)
            i += 1
            F = CC(F)
            layer(F)
        return dict(zip(results[:, 0], (results[:, 1])))

    def tildealt(G):
        pl = 0
        thr = 0


        def tilde(G):
            cliques = list(nx.enumerate_all_cliques(G))
            triads = [i for i in cliques if len(i) == 3]
            simm = []

            def combine(arr, s):
                return list(combinations(arr, s))

            for n in triads:
                for l in combine(n, 2):
                    simm.append(l)

            simmelian = []
            for i in simm:
                if i not in simmelian:
                    simmelian.append(i)




            nx.set_node_attributes(G, 0, name='threshold')
            for n in G.nodes:
                G.nodes[n]['threshold'] = thr
            F = ultravertical

            BC = Control_Centrality(F)

            nx.set_node_attributes(G, 0, name='relevance')

            for n in G.nodes:
                G.nodes[n]['relevance'] = np.random.beta(1, 2)
                initial_opinion.append(G.nodes[n]['relevance'])

            influence_matrix = np.matrix(np.zeros((num, num)))
            for i in G.nodes:
                influence_matrix[i, i] = 0.1
                for j in G.neighbors(i):
                        if i in top:
                            if j in top:
                                influence_matrix[i,j] = 0.1
                            elif j in bottom:
                                influence_matrix[i,j] = 0.1
                        elif i in bottom:
                            if j in top:
                                influence_matrix[i,j] = 0.1
                            elif j in bottom:
                                influence_matrix[i, j] = 0.1


            influence_matrix_correct = np.matrix(np.zeros((num, num)))
            for i in range(num):
                for j in range(num):
                    influence_matrix_correct[i, j] = influence_matrix[i, j] / np.sum(influence_matrix[i])

            probability_matrix = np.matrix(np.zeros((num, num)))
            for i in G.nodes:
                for j in G.neighbors(i):
                    if i == j:
                        probability_matrix[i, j] = 1
                    else:
                        probability_matrix[i, j] = 0.9


            datoni = []
            K = G.copy()
            t = 0
            influence_matrices = []

            def event():

                P = K.copy()

                influence_matrix_real = np.matrix(np.zeros((num, num)))
                influence_matrix_tilde = np.matrix(np.zeros((num, num)))
                for i in K.nodes:
                    influence_matrix_real[i, i] = influence_matrix[i, i]
                    for j in K.neighbors(i):
                        if random.random() < probability_matrix[i, j]:
                            if P.nodes[j]['relevance'] > P.nodes[j]['threshold']:
                                influence_matrix_real[i, j] = influence_matrix[i, j]
                            else:
                                influence_matrix_real[i, j] = 0
                        else:
                            influence_matrix_real[i, j] = 0
                for i in K.nodes:
                    influence_matrix_tilde[i, i] = influence_matrix_real[i, i] / np.sum(influence_matrix_real[i],
                                                                                        axis=1)
                    for j in K.nodes:
                        influence_matrix_tilde[i, j] = influence_matrix_real[i, j] / np.sum(influence_matrix_real[i],
                                                                                            axis=1
                                                                                            )
                influence_matrices.append(influence_matrix_tilde)
                for i in K.nodes:
                    opchange = [P.nodes[i]['relevance'] * influence_matrix_tilde[i, i]]
                    for j in K.neighbors(i):
                        opchange.append(influence_matrix_tilde[i, j] * P.nodes[j]['relevance'])
                    K.nodes[i]["relevance"] = np.sum(opchange)
                return K

            while t != steps:
                datelli = []
                datini = []
                t += 1
                event()
                for n in K.nodes:
                    datelli.append(K.nodes[n]['relevance'])
                    if K.nodes[n]['relevance'] > K.nodes[n]['threshold']:
                        datini.append(n)
                pd.DataFrame({'x': datelli})
                datoni.append(datelli)
            """
            plt.plot(datoni, 'k', alpha=0.1)
            plt.title('DeGroot (classic)')

            plt.plot(np.mean(datoni, axis=1), 'r--', label='mean')
            plt.plot(np.median(datoni, axis=1), 'b', label='median')
            plt.legend()
            plt.grid()
            plt.show()
            """

            def matrixMul(a, n):
                if (n <= 1):
                    return a
                else:
                    return np.matmul(matrixMul(a, n - 1), a)

            def matrixMultt(a, n):
                tempArr = a
                for i in range(0, n):
                    tempArr = influence_matrices[i] @ tempArr
                return tempArr


            plt.clf()


            datas.append(np.array(matrixMultt(influence_matrices[0], steps)[1][0]))

            banana=matrixMultt(influence_matrices[0], steps)[1][0].tolist()



            for i in range(num):
                influence[i].append(matrixMultt(influence_matrices[0], steps)[1][0].tolist()[0][i])

            X_axis = np.arange(len(G.nodes))


            plt.bar(X_axis + 0.2, np.asarray(matrixMul(influence_matrix_correct, steps))[1], 0.4, alpha=0.7,
                    color='blue', label='without randomness')
            plt.bar(X_axis - 0.2, np.asarray(matrixMultt(influence_matrices[0], steps))[1], 0.4, alpha=0.7, color='red',
                    label='with randomness')

            plt.legend()


        while pl != samples:
            print(100*(pl/samples),'%')
            pl += 1
            tilde(G)
    tildealt(G)
    plt.show()










    return influence



banana=test(G)




dfs = [pd.DataFrame({k: sample}) for k, sample in enumerate(banana)]


df = pd.concat(dfs, ignore_index=True, axis=1)
df = df.rename(columns={0: '0', 1: '1', 2:'2',3:'3', 4: '4', 5:'5',6: '6', 7: '7',8: '8', 9: '9',
                        10:'10',11:'11',12:'12',13:'13',14:'14',15:'15',16:'16',17:'17',18:'18',19:'19',
                        20:'20',21:'21',22:'22',23:'23',24:'24',25:'25',26:'26',27:'27',28:'28',29:'29',
                        30:'30',31:'31',32:'32',33:'33',34:'34',35:'35'})
df.to_excel('6x6notverticalminisimm0.95k.xlsx')


#df_melt = pd.melt(df.reset_index(), id_vars=['index'], value_vars=['influencesimtop', 'influencesimbottom',
#test(G,randomness=False,verticality=False)
#test(G,randomness=False,verticality=True)

#test(G,randomness=True,verticality=True)


df=pd.read_excel('6x6notverticalminisimm0.95k.xlsx')

g4=[0,2,3,7,8,12,13,15]
g4s5=[1,4,11,14]
s4=[6,9]
s5=[5,10]
datig4=[]
datis4=[]
datis5=[]
datig4s5=[]

for l in range(16):
    if l in g4:
        for n in df['{}'.format(l)]:
            datig4.append(n)
    elif l in s5:
        for n in df['{}'.format(l)]:
            datis5.append(n)
    elif l in s4:
        for n in df['{}'.format(l)]:
            datis4.append(n)
    elif l in g4s5:
        for n in df['{}'.format(l)]:
            datig4s5.append(n)


print('mean g4',np.mean(datig4))
print('median g4',np.median(datig4))
print('mean s4',np.mean(datis4))
print('median s4',np.median(datis4))
print('mean s5',np.mean(datis5))
print('median s5',np.median(datis5))
print('mean s5',np.mean(datig4s5))
print('median s5',np.median(datig4s5))



data=[]
data.append(datig4)
data.append(datis4)
data=(pd.DataFrame(data)).T
data=data.melt(var_name='group',value_name='values')
model = ols('values ~ C(group)', data=data).fit()
aov_table = sm.stats.anova_lm(model, typ=2)
print(aov_table)


data=[]
data.append(datig4s5)
data.append(datis4)
data=(pd.DataFrame(data)).T
data=data.melt(var_name='group',value_name='values')
model = ols('values ~ C(group)', data=data).fit()
aov_table = sm.stats.anova_lm(model, typ=2)
print(aov_table)







df=pd.read_excel('6x6notverticalmini0.15k.xlsx')
df1=pd.read_excel('6x6notverticalminisimm0.15k.xlsx')


g4=[1,3,6,9,11,12]
g4g5=[0,2,5,7,8,10,13,15]
g5=[4,14]
datig4=[]
datig5=[]
datig4g5=[]
for l in range(16):
    if l in g4:
        for n in df['{}'.format(l)]:
            datig4.append(n)
    elif l in g5:
        for n in df['{}'.format(l)]:
            datig5.append(n)
    elif l in g4g5:
        for n in df['{}'.format(l)]:
            datig4g5.append(n)
g41=[0,2,3,7,8,12,13,15]
g4s51=[1,4,11,14]
s41=[6,9]
s51=[5,10]
datig41=[]
datis41=[]
datis51=[]
datig4s51=[]



for l in range(16):
    if l in g41:
        for n in df1['{}'.format(l)]:
            datig41.append(n)
    elif l in s51:
        for n in df1['{}'.format(l)]:
            datis51.append(n)
    elif l in s41:
        for n in df1['{}'.format(l)]:
            datis41.append(n)
    elif l in g4s51:
        for n in df1['{}'.format(l)]:
            datig4s51.append(n)

print(len(datig4))
print(len(datig5))
print(len(datig4g5))
print(len(datis41))
print(len(datig41))
print(len(datis51))
print(len(datig4s51))

print(np.mean(datig4))
print(np.mean(datig5))
print(np.mean(datig4g5))
print(np.mean(datis41))
print(np.mean(datig41))
print(np.mean(datis51))
print(np.mean(datig4s51))

print(np.median(datig4))
print(np.median(datig5))
print(np.median(datig4g5))
print(np.median(datis41))
print(np.median(datig41))
print(np.median(datis51))
print(np.median(datig4s51))


data=[]
data.append(datig4)
data.append(datig41)
data.append(datig4s51)
data.append(datig4g5)
data.append(datig5)
data.append(datis51)
data.append(datis41)
data=(pd.DataFrame(data)).T
data=data.melt(var_name='group',value_name='values')
model = ols('values ~ C(group)', data=data).fit()
aov_table = sm.stats.anova_lm(model, typ=2)
print(aov_table)

data=[]
data.append(datig5)
data.append(datis51)
data=(pd.DataFrame(data)).T
data=data.melt(var_name='group',value_name='values')
model = ols('values ~ C(group)', data=data).fit()
aov_table = sm.stats.anova_lm(model, typ=2)
print(aov_table)

data=[]
data.append(datig4)
data.append(datig41)
data.append(datis41)
data.append(datig4g5)
data.append(datig4s51)
data=(pd.DataFrame(data)).T
data=data.melt(var_name='group',value_name='values')
model = ols('values ~ C(group)', data=data).fit()
aov_table = sm.stats.anova_lm(model, typ=2)
print(aov_table)


data=[]
data.append(datig4)
data.append(datig41)
data=(pd.DataFrame(data)).T
data=data.melt(var_name='group',value_name='values')
model = ols('values ~ C(group)', data=data).fit()
aov_table = sm.stats.anova_lm(model, typ=2)
print(aov_table)


data=[]
data.append(datis41)
data.append(datig4g5)
data.append(datig4s51)
data=(pd.DataFrame(data)).T
data=data.melt(var_name='group',value_name='values')
model = ols('values ~ C(group)', data=data).fit()
aov_table = sm.stats.anova_lm(model, typ=2)
print(aov_table)

data=[]
data.append(datig4g5)
data.append(datig4s51)
data=(pd.DataFrame(data)).T
data=data.melt(var_name='group',value_name='values')
model = ols('values ~ C(group)', data=data).fit()
aov_table = sm.stats.anova_lm(model, typ=2)
print(aov_table)
